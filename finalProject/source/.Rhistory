aes(date, count, group = type, colour = factor(type)),
main = paste("Average Likes/Shares/Comments for per post of page", "Fox News")) +
geom_point() +
geom_line() +
theme(axis.text=element_text(size=5))
ggsave(plot = last_plot(), "graphName", width = 20, limitsize = FALSE)
page <- getPage(page = "cnn", token = fbToken, n = 2000, api = apiVersion)
page$datatime <- format.facebook.date(page$created_time)
page$month <- month(page$datatime)
page$year <- year(page$datatime)
pageAggr <- page %>%
group_by(month, year) %>%
summarise(likesCount = mean(likes_count), commentsCount = mean(comments_count), sharesCount = mean(shares_count))
pageAggr$date <- paste(pageAggr$year, '-', pageAggr$month, sep = "")
pageAggr <- pageAggr %>%
gather("type", "count", - month, - year, -date)
p <- ggplot(pageAggr,
aes(date, count, group = type, colour = factor(type))) +
ggtitle("Average Likes/Shares/Comments for per post of page CNN News") +
geom_point() +
geom_line() +
theme(axis.text=element_text(size=5))
ggsave(plot = last_plot(), "graphName", width = 20, limitsize = FALSE)
p
page <- getPage(page = "FoxNews", token = fbToken, n = 2000, api = apiVersion)
fbToken <- setConnector(TRUE)
page <- getPage(page = "FoxNews", token = fbToken, n = 2000, api = apiVersion)
page$datatime <- format.facebook.date(page$created_time)
page$month <- month(page$datatime)
page$year <- year(page$datatime)
pageAggr <- page %>%
group_by(month, year) %>%
summarise(likesCount = mean(likes_count), commentsCount = mean(comments_count), sharesCount = mean(shares_count))
pageAggr$date <- paste(pageAggr$year, '-', pageAggr$month, sep = "")
pageAggr <- pageAggr %>%
gather("type", "count", - month, - year, -date)
p <- ggplot(pageAggr,
aes(date, count, group = type, colour = factor(type))) +
ggtitle("Average Likes/Shares/Comments for per post of page Fox News") +
geom_point() +
geom_line() +
theme(axis.text=element_text(size=5))
p
page <- getPage("vox", token, n = 5000)
page <- getPage("vox", fbToken, n = 5000)
page[which.max(page$likes_count), ]
mostRepliedPost <- page[which.max(page$likes_count), ]
View(mostRepliedPost)
View(mostRepliedPost)
page <- getPage("FoxNews", fbToken, n = 5000)
page
mostRepliedPost <- page[which.max(page$likes_count), ]
mostRepliedPost
View(mostRepliedPost)
page <- getPage("FoxNews", fbToken, n = 2000)
mostRepliedPost <- page[which.max(page$likes_count), ]
mostRepliedPost
mostRepliedPost
View(mostRepliedPost)
mostRepliedPost$message
mostRepliedPost$id
reactions <- getReactions(mostRepliedPost$id, token = fbToken)
reactions <- getReactions(mostRepliedPost$id, token = fbToken, api = apiVersion)
reactions
View(page)
View(page)
mostRepliedPost <- page[order(page$likes_count), ]
mostRepliedPost
page <- page[order(page$likes_count), ]
page[3, ]
page[which(id = "15704546335_10154108339971336)", ]
# get reactions of the post
reactions <- getReactions(mostRepliedPost$id, token = fbToken, api = apiVersion)
page <- page[order(page$likes_count), ]
page[which(id = "15704546335_10154108339971336"), ]
page[which(page$id = "15704546335_10154108339971336"), ]
page[which(page$id == "15704546335_10154108339971336"), ]
reactions <- getReactions(page$id, token = fbToken, api = apiVersion)
View(reactions)
View(reactions)
library(grep)
install.packages("grep")
selectedPage <- page[which(grepl(page$message, "Trump")), ]
selectedPage <- page[grep("Trump", page$message), ]
selectedPage
selectedPage <- page[grep("Trump", page$message), ]
View(selectedPage)
View(selectedPage)
pageTrump <- page[grep("Trump", page$message), ]
pageHillary <- page[grep("Hillary", page$message), ]
pageHillary
reactionsTrump <- getReactions(pageTrump$id, token = fbToken, api = apiVersion)
pageHillary <- page[grep("Hillary", page$message), ]
reactionsHillary <- getReactions(pageTrump$id, token = fbToken, api = apiVersion)
View(reactionsTrump)
View(reactionsTrump)
pageAggr <- reactionsTrump %>%
gather("type", "count", -id)
pageAggr
ggplot(pageAggr, aes(id, count, group = type, fill = `count`)) +
post <- page[which(page$id == "15704546335_10154108339971336"), ]
ggplot(pageAggr, aes(id, count, group = type, fill = count,  group = type))
p <- ggplot(pageAggr,
aes(date, count, group = type, colour = factor(type))) +
ggtitle("graphName") +
geom_point()
p
View(pageAggr)
View(pageAggr)
p <- ggplot(pageAggr,
aes(id, count, group = type, colour = factor(type))) +
ggtitle("graphName") +
geom_point()
p
pageAggrTrump <- reactionsTrump %>%
gather("type", "count", -id)
p <- ggplot(pageAggr,
aes(id, count, group = type, colour = factor(type))) +
ggtitle("graphName") +
geom_point()
p
pageAggrTrump <- reactionsTrump %>%
gather("type", "count", -id)
p <- ggplot(pageAggrTrump,
aes(id, count, group = type, colour = factor(type))) +
ggtitle("Reaction Distrubtion for Post related to Trump") +
geom_point()
p
p <- ggplot(pageAggrTrump,
aes(id, count, group = type, colour = factor(type))) +
ggtitle("Reaction Distrubtion for Post related to Trump") +
geom_point() +
geom_bar()
p
p <- ggplot(pageAggrTrump,
aes(id, count, group = type, colour = factor(type))) +
ggtitle("Reaction Distrubtion for Post related to Trump") +
geom_point() +
geom_bar(stat="identity")
p
p <- ggplot(pageAggrTrump,
aes(id, count, group = type, colour = factor(type))) +
ggtitle("Reaction Distrubtion for Post related to Trump") +
geom_bar(stat="identity")
p
p <- ggplot(pageAggrTrump,
aes(id, count, group = type, colour = factor(type))) +
ggtitle("Reaction Distrubtion for Post related to Trump") +
geom_bar(stat="identity") +
theme(axis.title.x=element_blank(),
axis.text.x=element_blank(),
axis.ticks.x=element_blank())
p
pageAggrTrump <- merge(x = pageAggrTrump, y = pageTrump, by = "id", all.x = TRUE)
View(pageAggrTrump)
View(pageAggrTrump)
p <- ggplot(pageAggrTrump,
aes(created_time, count, group = type, colour = factor(type))) +
ggtitle("Reaction Distrubtion for Post related to Trump") +
geom_bar(stat="identity") +
theme(axis.title.x=element_blank(),
axis.text.x=element_blank(),
axis.ticks.x=element_blank())
p
p <- ggplot(pageAggrTrump,
aes(created_time, count, group = type.x, colour = factor(type))) +
ggtitle("Reaction Distrubtion for Post related to Trump") +
geom_bar(stat="identity") +
theme(axis.title.x=element_blank(),
axis.text.x=element_blank(),
axis.ticks.x=element_blank())
p
p <- ggplot(pageAggrTrump,
aes(created_time, count, group = type.x, colour = factor(type.x))) +
ggtitle("Reaction Distrubtion for Post related to Trump") +
geom_bar(stat="identity") +
theme(axis.title.x=element_blank(),
axis.text.x=element_blank(),
axis.ticks.x=element_blank())
p
p <- ggplot(pageAggrTrump,
aes(created_time, count, group = type.x, colour = factor(type.x))) +
ggtitle("Reaction Distrubtion for Post related to Trump") +
geom_bar(stat="identity")
p
p <- ggplot(pageAggrTrump,
aes(created_time, count, group = type.x, colour = factor(type.x))) +
ggtitle("Reaction Distrubtion for Post related to Trump") +
geom_bar(stat="identity") +
theme(axis.text=element_text(size=5))
p
p <- ggplot(pageAggrTrump,
aes(created_time, count, group = type.x) +
ggtitle("Reaction Distrubtion for Post related to Trump") +
geom_bar(stat="identity") +
theme(axis.title.x=element_blank(),
axis.text.x=element_blank(),
axis.ticks.x=element_blank())
p
post <- page[which(page$id == "15704546335_10154108339971336"), ]
# get reactions of the post
}
p <- ggplot(pageAggrTrump,
aes(created_time, count, group = type.x)) +
ggtitle("Reaction Distrubtion for Post related to Trump") +
geom_bar(stat="identity") +
theme(axis.title.x=element_blank(),
axis.text.x=element_blank(),
axis.ticks.x=element_blank())
p
p <- ggplot(pageAggrTrump,
aes(created_time, count, group = type.x, colour = factor(type.x))) +
ggtitle("Reaction Distrubtion for Post related to Trump") +
geom_bar(stat="identity") +
theme(axis.title.x=element_blank(),
axis.text.x=element_blank(),
axis.ticks.x=element_blank())
p
post <- page[which(page$id == "15704546335_10154108339971336"), ]
p <- ggplot(pageAggrTrump,
aes(created_time, count, group = type.x, fill = factor(type.x))) +
ggtitle("Reaction Distrubtion for Post related to Trump") +
geom_bar(stat="identity") +
theme(axis.title.x=element_blank(),
axis.text.x=element_blank(),
axis.ticks.x=element_blank())
p
pageAggrHillary <- reactionsHillary %>%
gather("type", "count", -id)
pageAggrHillary <- merge(x = pageAggrHillary, y = pageHillary, by = "id", all.x = TRUE)
p <- ggplot(pageAggrHillary,
aes(created_time, count, group = type.x, fill = factor(type.x))) +
ggtitle("Reaction Distrubtion for Post related to Trump") +
geom_bar(stat="identity") +
theme(axis.title.x=element_blank(),
axis.text.x=element_blank(),
axis.ticks.x=element_blank())
p
p <- ggplot(pageAggrHillary,
aes(created_time, count, group = type.x, fill = factor(type.x))) +
ggtitle("Reaction Distrubtion for Post related to Hillary") +
geom_bar(stat="identity") +
scale_y_continuous(limits = c(0, 5000)) +
theme(axis.title.x=element_blank(),
axis.text.x=element_blank(),
axis.ticks.x=element_blank())
p
require(tm)
require(tm)
View(reactionsTrump)
View(reactionsTrump)
cloud(reactionsTrump$likes_count ~ reactionsTrump$sad_count * reactionsTrump$angry_count,
xlab = "HSgrad",
ylab = "Illiteracy",
zlab = "Income",
main = "3D plot of States",
distance = .4)
cloud(reactionsTrump$likes_count ~ reactionsTrump$sad_count * reactionsTrump$angry_count,
xlab = "Likes",
ylab = "Sad",
zlab = "Angry",
main = "3D plot of Reactions",
distance = .4)
mfrow3d(nr = 1, nc = 1, sharedMouse = TRUE)
library(rgl)
library(rglwidget)
mfrow3d(nr = 1, nc = 1, sharedMouse = TRUE)
plot3d(reactionsTrump$likes_count , reactionsTrump$sad_count, reactionsTrump$angry_count,
col="blue", size=10, pch = 21,
xlab = "Income",
ylab = "HS Grad",
zlab = "Life Exp",
main = "Income VS HS Grad VS Life Exp"
)
rglwidget()
mfrow3d(nr = 1, nc = 1, sharedMouse = TRUE)
plot3d(reactionsTrump$likes_count , reactionsTrump$sad_count, reactionsTrump$angry_count,
col="red", size = 8, pch = 16,
xlab = "Income",
ylab = "HS Grad",
zlab = "Life Exp",
main = "Income VS HS Grad VS Life Exp"
)
rglwidget()
cloud(reactionsHillary$likes_count ~ reactionsHillary$sad_count * reactionsHillary$angry_count,
xlab = "Likes",
ylab = "Sad",
zlab = "Angry",
main = "3D plot of Reactions",
distance = .4)
cloud(reactionsTrump$likes_count ~ reactionsTrump$sad_count * reactionsTrump$angry_count,
xlab = "Likes",
ylab = "Sad",
zlab = "Angry",
main = "3D plot of Reactions",
distance = .4)
cloud(reactionsTrump$likes_count ~ reactionsTrump$sad_count * reactionsTrump$angry_count,
xlab = "Likes",
ylab = "Sad",
zlab = "Angry",
main = "3D plot of Reactions for Trump",
distance = .4)
cloud(reactionsTrump$likes_count ~ reactionsTrump$sad_count * reactionsTrump$angry_count,
xlab = "Likes",
ylab = "Sad",
zlab = "Angry",
main = "3D plot of Reactions for Trump",
distance = .4,
col = "red",
pch = 19)
View(pageTrump)
View(pageTrump)
postTrump <- pageTrump[max(pageTrump$likes_count), ]
postTrump
postTrump <- pageTrump[whiich(pageTrump$likes_count == max(pageTrump$likes_count), ]
}
postTrump <- pageTrump[which(pageTrump$likes_count == max(pageTrump$likes_count)), ]
postTrump
postTrump <- getPost(post = postTrump$id, n = 3000, token = fbToken)
postTrump
postMessage <- (postTrump$comments)$message
postMessage
docs <- Corpus(VectorSource(postMessage))
toSpace <- content_transformer(function (x, pattern) gsub(pattern, " ", x))
docs <- tm_map(docs, toSpace, "/")
docs <- tm_map(docs, toSpace, "@")
docs <- tm_map(docs, toSpace, "\\|")
docs <- tm_map(docs, content_transformer(tolower))
docs <- tm_map(docs, function(x) iconv(enc2utf8(x), sub = "byte"))
docs <- tm_map(docs, content_transformer(tolower))
docs <- tm_map(docs, function(x) iconv(x, to='UTF-8-MAC', sub='byte'))
docs <- tm_map(docs, content_transformer(tolower))
docs <- tm_map(docs, removeNumbers)
docs <- tm_map(docs, removeWords, stopwords("english"))
docs <- tm_map(docs, removePunctuation)
docs <- tm_map(docs, stripWhitespace)
docs <- tm_map(docs, steamDocument)
dtm <- TermDocumentMatrix(docs)
m <- as.matrix(dtm)
v <- sort(rowSums(m), decreasing = TRUE)
d <- data.frame(word = names(v), freq = v)
head(d, 10)
install.packages("wordcloud")
library(wordcloud)
wordcloud(works = d$word, freq = d$freq, min.freq = 1,
max.words = 200, random.order = FALSE, rot.per = 0.35)
wordcloud(words = d$word, freq = d$freq, min.freq = 1,
max.words = 200, random.order = FALSE, rot.per = 0.35)
d
head(d, 20)
wordcloud(words = d$word, freq = d$freq, min.freq = 1,max.words=200, random.order=FALSE, rot.per=0.35,colors=brewer.pal(8, "Dark2"))
wordcloud(words = d$word, freq = d$freq, min.freq = 1,
max.words = 300, random.order = FALSE,
rot.per = 0.35, colors = brewer.pal(8, "Dark2"))
p <- wordcloud(words = d$word, freq = d$freq, min.freq = 1,
max.words = 300, random.order = FALSE,
rot.per = 0.35, colors = brewer.pal(8, "Dark2"))
textMiningUtil(postMessage)
textMiningUtil <- function(postMessage) {
docs <- Corpus(VectorSource(postMessage))
toSpace <- content_transformer(function (x, pattern) gsub(pattern, " ", x))
docs <- tm_map(docs, toSpace, "/")
docs <- tm_map(docs, toSpace, "@")
docs <- tm_map(docs, toSpace, "\\|")
# convert the text to lower case
docs <- tm_map(docs, function(x) iconv(x, to='UTF-8-MAC', sub='byte'))
docs <- tm_map(docs, content_transformer(tolower))
# remove numbers
docs <- tm_map(docs, removeNumbers)
# remove English common stop words
docs <- tm_map(docs, removeWords, stopwords("english"))
# remove punctuatios
docs <- tm_map(docs, removePunctuation)
# remove extra white space
docs <- tm_map(docs, stripWhitespace)
# text streaming
docs <- tm_map(docs, steamDocument)
dtm <- TermDocumentMatrix(docs)
m <- as.matrix(dtm)
v <- sort(rowSums(m), decreasing = TRUE)
d <- data.frame(word = names(v), freq = v)
head(d, 20)
p <- wordcloud(words = d$word, freq = d$freq, min.freq = 1,
max.words = 300, random.order = FALSE,
rot.per = 0.35, colors = brewer.pal(8, "Dark2"))
p
}
textMiningUtil(postMessage)
textMiningUtil <- function(postMessage) {
docs <- Corpus(VectorSource(postMessage))
toSpace <- content_transformer(function (x, pattern) gsub(pattern, " ", x))
docs <- tm_map(docs, toSpace, "/")
docs <- tm_map(docs, toSpace, "@")
docs <- tm_map(docs, toSpace, "\\|")
# convert the text to lower case
docs <- tm_map(docs, function(x) iconv(x, to='UTF-8-MAC', sub='byte'))
docs <- tm_map(docs, content_transformer(tolower))
# remove numbers
docs <- tm_map(docs, removeNumbers)
# remove English common stop words
docs <- tm_map(docs, removeWords, stopwords("english"))
# remove punctuatios
docs <- tm_map(docs, removePunctuation)
# remove extra white space
docs <- tm_map(docs, stripWhitespace)
dtm <- TermDocumentMatrix(docs)
m <- as.matrix(dtm)
v <- sort(rowSums(m), decreasing = TRUE)
d <- data.frame(word = names(v), freq = v)
head(d, 20)
p <- wordcloud(words = d$word, freq = d$freq, min.freq = 1,
max.words = 300, random.order = FALSE,
rot.per = 0.35, colors = brewer.pal(8, "Dark2"))
p
}
textMiningUtil(postMessage)
postHillary <- pageHillary[which(pageHillary$likes_count == max(pageHillary$likes_count)), ]
postHillary <- getPost(post = popostHillarystTrump$id, n = 3000, token = fbToken)
postHillary <- pageHillary[which(pageHillary$likes_count == max(pageHillary$likes_count)), ]
postHillary <- getPost(post = popostHillary$id, n = 3000, token = fbToken)
postHillary <- pageHillary[which(pageHillary$likes_count == max(pageHillary$likes_count)), ]
postHillary <- getPost(post = postHillary$id, n = 3000, token = fbToken)
fbToken <- setConnector(TRUE)
postHillary <- pageHillary[which(pageHillary$likes_count == max(pageHillary$likes_count)), ]
postHillary <- getPost(post = postHillary$id, n = 3000, token = fbToken)
postMessage <- (postHillary$comments)$message
textMiningUtil(postMessage)
users <- getShares(post = post = postTrump$id, n = 2000)
users <- getShares(post = postTrump$id, n = 2000)
users <- getShares(post = postTrump$id, n = 2000, token = fbToken)
users <- getShares(post = postTrump$id, n = 2000, token = fbToken, api = apiVersion)
users <- getShares(post = postTrump$id, n = 2000, token = fbToken)
postTrump$id
postTrump <- pageTrump[which(pageTrump$likes_count == max(pageTrump$likes_count)), ]
postTrump
users <- getShares(post = postTrump$id, n = 2000, token = fbToken)
users
postTrump$id
users <- getShares(post = postTrump$id, n = 2000, token = fbToken)
users
testFriendsAPIs <- function() {
ownerInfo <- getUsers("me", fbToken, private_info=TRUE)
friendsList <- getFriends(token = fbToken, simplify = FALSE)
friendsInfo <- getUsers(friendsList$id, fbToken, private_info = TRUE)
}
testFriendsAPIs()
testFriendsAPIs <- function() {
ownerInfo <- getUsers("me", fbToken, private_info=TRUE)
friendsList <- getFriends(token = fbToken, simplify = FALSE)
friendsList
friendsInfo <- getUsers(friendsList$id, fbToken, private_info = TRUE)
friendsInfo
}
testFriendsAPIs()
print.data.frame(friendsInfo)
ownerInfo <- getUsers("me", fbToken, private_info=TRUE)
friendsList <- getFriends(token = fbToken, simplify = FALSE)
friendsInfo <- getUsers(friendsList$id, fbToken, private_info = TRUE)
print.data.frame(friendsInfo)
knitr::opts_chunk$set(echo = TRUE, fig.align="center")
urlBase <- "https://graph.facebook.com/"
apiVersion <- "v2.10"
setEnv <- function() {
setwd("/Users/xinhuang/Google Drive/CSC 522 R Language Programming /Final Project/source")
require(devtools)
require (Rfacebook)
require(rjson)
require(tm)
require(RCurl)
require(wordcloud)
require(igraph)
require("scales")
library(plyr)
library(dplyr)
library(tidyr)
library(lattice)
library(ggplot2)
library(lubridate)
library(rgl)
library(rglwidget)
library(wordcloud)
}
setEnv()
setConnector <- function(isToken, isOath = FALSE, isToCreateNewOath = FALSE) {
appSetting <- fromJSON(file = "app_setting.json")
if (isOath) {
if (isToCreateNewOath) {
fbOauth <- fbOAuth(app_id = appSetting$app_id,
app_secret = appSetting$app_secret,
extended_permissions = TRUE)
save(fb_oauth, file = "fb_oauth")
return(fbOauth)
} else {
return(fbOauth <- load("fb_oauth"))
}
} else {
# Connect to Facebook API via Authentication Toke
return(appSetting$token)
}
}
fbToken <- setConnector(TRUE)
testFriendsAPIs <- function() {
# get my own user information includ internal user id
ownerInfo <- getUsers("me", fbToken, private_info=TRUE)
# get user ID of my friends
friendsList <- getFriends(token = fbToken, simplify = FALSE)
# acquire user information
friendsInfo <- getUsers(friendsList$id, fbToken, private_info = TRUE)
# print out some columnbs of friendsInfo
print.data.frame(friendsInfo[ , 2 : 7])
}
testFriendsAPIs()
